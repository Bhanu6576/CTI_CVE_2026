{
  "id": "CVE-2026-21869",
  "title": "Security Advisory: CVE-2026-21869",
  "severity": "HIGH",
  "cvssScore": 8.8,
  "cvssVector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H",
  "publishedDate": "2026-01-08T00:16:00.297",
  "description": "llama.cpp is an inference of several LLM models in C/C++. In commits 55d4206c8 and prior, the n_discard parameter is parsed directly from JSON input in the llama.cpp server's completion endpoints without validation to ensure it's non-negative. When a negative value is supplied and the context fills up, llama_memory_seq_rm/add receives a reversed range and negative offset, causing out-of-bounds memory writes in the token evaluation loop. This deterministic memory corruption can crash the process or enable remote code execution (RCE). There is no fix at the time of publication.",
  "url": "https://nvd.nist.gov/vuln/detail/CVE-2026-21869",
  "references": [
    "https://github.com/ggml-org/llama.cpp/security/advisories/GHSA-8947-pfff-2f3c"
  ],
  "summary": "CVE-2026-21869 is a HIGH severity vulnerability with a CVSS score of 8.8. llama.cpp is an inference of several LLM models in C/C++. In commits 55d4206c8 and prior, the n_discard parameter is parsed directly from JSON input in the llama.cpp server's completion endpoints with...",
  "impact": "HIGH: This vulnerability presents a significant risk to affected systems. Exploitation could result in unauthorized access, data exposure, or service degradation.",
  "remediation": "1. Review the CVE details and assess the impact on your systems\n2. Check if any of your systems or applications are affected\n3. Apply vendor-provided patches or updates as soon as possible\n4. If patches are not available, implement compensating controls\n5. Monitor systems for signs of exploitation\n6. Review and update security policies as needed",
  "timestamp": "2026-01-08T00:51:43.658Z"
}